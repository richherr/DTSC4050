{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC4050/blob/main/Week_12-Classification_I/From_Lines_to_Likelihood_Podcast_Companion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# --- Probability Calculation Example ---\n",
        "\n",
        "# Define the parameters from the model\n",
        "beta_0 = -2  # Intercept (log odds when visits = 0)\n",
        "beta_1 = 0.5 # Coefficient for website visits\n",
        "\n",
        "# Number of website visits\n",
        "visits = 4\n",
        "\n",
        "# Calculate the log odds (T)\n",
        "T = beta_0 + beta_1 * visits\n",
        "print(f\"Log Odds (T) using beta_0 + beta_1 * visits where visits = 4: {T}\")\n",
        "\n",
        "# Sigmoid function to calculate probability\n",
        "def sigmoid(t):\n",
        "  return 1 / (1 + np.exp(-t))\n",
        "\n",
        "# Calculate the probability\n",
        "probability = sigmoid(T)\n",
        "print(f\"Probability of clicking: {probability:.2f}\")\n",
        "\n",
        "# --- Coefficient Interpretation ---\n",
        "# Transcript explanation of the 0.5 coefficient\n",
        "\n",
        "print(f\"For each additional visit, the log odds of clicking increase by {beta_1}\")\n",
        "\n",
        "# Exponentiate the coefficient to get the change in odds\n",
        "odds_ratio = np.exp(beta_1)\n",
        "print(f\"Odds increase by a factor of {odds_ratio:.2f} or {((odds_ratio - 1) * 100):.0f}%\")\n",
        "\n",
        "# --- Confusion Matrix Example ---\n",
        "\n",
        "# Define the confusion matrix values\n",
        "true_positives = 40\n",
        "false_negatives = 10\n",
        "false_positives = 5\n",
        "true_negatives = 45\n",
        "\n",
        "# Create the confusion matrix as a 2x2 NumPy array\n",
        "confusion_matrix = np.array([[true_negatives, false_positives],\n",
        "                           [false_negatives, true_positives]])\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix)\n",
        "\n",
        "# --- Precision and Recall Calculation ---\n",
        "# As described in the transcript\n",
        "\n",
        "# Calculate precision\n",
        "precision = true_positives / (true_positives + false_positives)\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "\n",
        "# Calculate recall\n",
        "recall = true_positives / (true_positives + false_negatives)\n",
        "print(f\"Recall: {recall:.2f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Odds (T) using beta_0 + beta_1 * visits where visits = 4: 0.0\n",
            "Probability of clicking: 0.50\n",
            "For each additional visit, the log odds of clicking increase by 0.5\n",
            "Odds increase by a factor of 1.65 or 65%\n",
            "Confusion Matrix:\n",
            "[[45  5]\n",
            " [10 40]]\n",
            "Precision: 0.89\n",
            "Recall: 0.80\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fi70xaP0I6X",
        "outputId": "e7325f9a-ffac-4c95-844e-bfee7983bcbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "1.  **Probability Calculation:**\n",
        "    \n",
        "    * Variables `beta_0`, `beta_1`, and `visits` are defined based on the example in the transcript.\n",
        "    * The log odds (`T`) is calculated using the linear equation.\n",
        "    * The `sigmoid` function is defined to convert log odds to a probability between 0 and 1.\n",
        "    * The probability of clicking is calculated and printed.\n",
        "2.  **Coefficient Interpretation:**\n",
        "    \n",
        "    * The code prints the direct interpretation of `beta_1` as the change in log odds.\n",
        "    * It then calculates the odds ratio by exponentiating `beta_1` to show how the odds of clicking change multiplicatively.\n",
        "3.  **Confusion Matrix:**\n",
        "    \n",
        "    * The values for true positives, false negatives, false positives, and true negatives are taken directly from the transcript.\n",
        "    * These values are used to create a 2x2 NumPy array representing the confusion matrix.\n",
        "4.  **Precision and Recall:**\n",
        "    \n",
        "    * Precision and recall are calculated using the formulas from the transcript, based on the values in the confusion matrix.\n",
        "    * The calculated precision and recall values are printed."
      ],
      "metadata": {
        "id": "HAPkC9xM0I6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log Odds:**\n",
        "\n",
        "* In logistic regression, the model predicts the *log odds* of the outcome (e.g., the log odds of a customer clicking).\n",
        "* The equation `T = beta_0 + beta_1 * visits` calculates this log odds (T).\n",
        "* `beta_1` (0.5 in the example) represents the change in the log odds for every one-unit increase in the predictor variable (number of visits).\n",
        "* So, \"For each additional visit, the log odds of clicking increase by 0.  5\" means that the value of T goes up by 0.5 for each extra visit.\n",
        "\n",
        "**Odds:**\n",
        "\n",
        "* \"Odds\" is a different way of expressing the likelihood of an event, compared to probability.\n",
        "* To understand the effect of the predictor on the *odds* themselves, we need to transform the coefficient.\n",
        "* We do this by exponentiating the coefficient (`np.exp(beta_1)` or `e^beta_1`).\n",
        "* In the example, `exp(0.5)` is approximately 1.  65.\n",
        "* This means that the *odds* of clicking are multiplied by 1.65 for each additional visit.\n",
        "* We can also express this as a percentage increase: (1.  65 - 1) \\* 100% = 65%.\n",
        "* So, \"Odds increase by a factor of 1.  65 or 65%\" means that the likelihood of clicking increases by 65% for each extra visit.\n",
        "\n",
        "**In summary:**\n",
        "\n",
        "* Logistic regression models log odds, and the coefficient directly shows the change in log odds.\n",
        "* To interpret the effect on odds, you exponentiate the coefficient. This gives you the factor by which the odds change, which can also be expressed as a percentage increase."
      ],
      "metadata": {
        "id": "eTfZQ6Ya2Wzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# --- Generate Synthetic Data ---\n",
        "# Based on T = beta_0 + beta_1 * visits, but with some randomness\n",
        "\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "n_samples = 1000  # Number of data points\n",
        "beta_0 = -2\n",
        "beta_1 = 0.5\n",
        "\n",
        "# Generate website visits\n",
        "visits = np.random.randint(0, 20, n_samples)  # Visits between 0 and 19\n",
        "\n",
        "# Calculate log odds (T) with some noise added\n",
        "T = beta_0 + beta_1 * visits + np.random.normal(0, 1, n_samples)\n",
        "\n",
        "# Calculate probabilities using the sigmoid function\n",
        "def sigmoid(t):\n",
        "    return 1 / (1 + np.exp(-t))\n",
        "\n",
        "probabilities = sigmoid(T)\n",
        "\n",
        "# Convert probabilities to binary outcomes (0 or 1)\n",
        "# You can adjust the threshold to see how it affects the confusion matrix\n",
        "threshold = 0.5\n",
        "clicks = (probabilities > threshold).astype(int)\n",
        "\n",
        "# Create a Pandas DataFrame\n",
        "data = pd.DataFrame({'visits': visits, 'probabilities': probabilities, 'clicks': clicks})\n",
        "\n",
        "# --- Logistic Regression Model ---\n",
        "# Using scikit-learn for comparison and to show the process\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = data[['visits']]  # Independent variable\n",
        "y = data['clicks']    # Dependent variable\n",
        "\n",
        "# The randomness will provide slightly different results from previous example\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# --- Confusion Matrix ---\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# --- Interpretation ---\n",
        "# The confusion matrix is a 2x2 matrix:\n",
        "# [[TN FP]\n",
        "#  [FN TP]]\n",
        "# TN: True Negatives (correctly predicted no click)\n",
        "# FP: False Positives (predicted click, but no click)\n",
        "# FN: False Negatives (predicted no click, but click)\n",
        "# TP: True Positives (correctly predicted click)\n",
        "# Precision = TP / (TP + FP)\n",
        "# Recall = TP / (TP + FN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jRusiRN1o-b",
        "outputId": "ff2330de-da8b-4409-e76f-4df8346629ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 40   6]\n",
            " [  9 145]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**:\n",
        "\n",
        "* Precision: ...out of all the times that our model predicted a yes, a positive outcome, how often was it actually a yes?\n",
        "* Recall: ...out of all the actual yes cases, how many did our model correctly identify?"
      ],
      "metadata": {
        "id": "CFrxSQRo3ejK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "1.  **Generate Synthetic Data:**\n",
        "    \n",
        "    * `np.random.seed(42)`: Ensures the data generation is the same every time you run the code, for reproducibility.\n",
        "    * `n_samples`, `beta_0`, `beta_1`: Define the number of data points and the parameters of the logistic regression equation.\n",
        "    * `visits = np.random.randint(0, 20, n_samples)`:  Creates an array of random integer values between 0 and 19 (inclusive) to represent the number of website visits for each user.\n",
        "    * `T = beta_0 + beta_1 \\* visits + np.random.normal(0, 1, n_samples)`: Calculates the log-odds (T) using the given equation but adds random noise (`np.random.normal(0, 1, n_samples)`) to make the data more realistic. This noise simulates other factors that might influence clicking behavior.\n",
        "    * `sigmoid(T)`: Converts the log-odds to probabilities using the sigmoid function.\n",
        "    * `clicks = (probabilities > threshold).astype(int)`:  Turns the probabilities into binary outcomes (0 or 1) by applying a threshold. If the probability is greater than the threshold, it's considered a \"click\" (1); otherwise, \"no click\" (0).\n",
        "    * `pd.DataFrame(...)`:  Organizes the generated data into a Pandas DataFrame for easier handling.\n",
        "2.  **Logistic Regression Model:**\n",
        "    \n",
        "    * `X = data[['visits']]`, `y = data['clicks']`:  Prepares the data for scikit-learn. `X` is the independent variable (visits), and `y` is the dependent variable (clicks).\n",
        "    * `train_test_split(...)`:  Splits the data into training and testing sets. The model is trained on the training set and evaluated on the testing set.\n",
        "    * `LogisticRegression()`: Creates a logistic regression model object.\n",
        "    * `model.fit(X_train, y_train)`: Trains the model on the training data.\n",
        "    * `model.predict(X_test)`:  Makes predictions on the test data.\n",
        "3.  **Confusion Matrix:**\n",
        "    \n",
        "    * `confusion_matrix(y_test, y_pred)`:  Calculates the confusion matrix by comparing the true outcomes (`y_test`) with the model's predictions (`y_pred`).\n",
        "    * The confusion matrix is printed to the console."
      ],
      "metadata": {
        "id": "xdSybrZn1lK8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}