{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC4050/blob/main/Week_01-Introduction/Week_01_Overview_and_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXh7hW2UYJA9"
   },
   "source": [
    "# Week 01 - Overview and Summary\n",
    "\n",
    "Here's an overview and summary of the key concepts, tools, and techniques discussed, organized by topic:\n",
    "\n",
    "**Data Science and the Data Science Lifecycle**\n",
    "*   Data science is a rapidly growing field that uses a systematic approach to extract value from data.\n",
    "*   The data science lifecycle has five main steps: defining the problem, data collection and preparation, data exploration and analysis, model building and evaluation, and deployment and maintenance.\n",
    "*   **Defining the problem** involves understanding stakeholder requirements, framing the problem, setting success criteria, prioritizing, and documenting.\n",
    "*   Data scientists need to be curious and organized, as well as proficient in statistical functions.\n",
    "*   Data scientists analyze raw data, build data models, and infer results.\n",
    "\n",
    "**Data and Data Analysis**\n",
    "*   **Data** are sets of values of qualitative or quantitative variables about one or more persons or objects. Data can be transformed into information when viewed in context.\n",
    "*   **Data analysis** includes quantitative analysis (statistical) which uses patterns and data visualization and qualitative analysis which produces generic information from non-data forms of media.\n",
    "*   Data are measured, collected, reported, and analyzed and are used to create data visualizations such as graphs, tables, or images.\n",
    "*   **Exploratory data analysis (EDA)** is used to summarize the main characteristics of a dataset, often using statistical graphics and other data visualization methods. EDA is used to explore data, find patterns, and formulate hypotheses.\n",
    "*   **Data storytelling** is the skill to craft a narrative by leveraging data, which is then contextualized, and finally presented to an audience. It utilizes data analysis, statistics, data visualization, qualitative and contextual analysis, and presentation. A data story is a narrative constructed around a set of data that puts it into context and frames the broader implications.\n",
    "*   Data visualizations are an essential part of data stories that help deliver various points in a narrative.\n",
    "*   **Data quality** should be addressed for each individual measurement, each individual observation, and for the entire data set.\n",
    "\n",
    "**Key Statistical Concepts**\n",
    "*   **Population:** the source of data to be collected.\n",
    "*   **Sample:** a portion of the population.\n",
    "*  **Variable:** any data item that can be measured or counted.\n",
    "*   **Descriptive statistics** summarize the characteristics of a population.\n",
    "*   **Inferential statistics** makes predictions for a population.\n",
    "*   **Measures of central tendency** include the mean (average), median (central value), and mode (most frequent value).\n",
    "\n",
    "**Feature Engineering and Selection**\n",
    "*  **Feature engineering** involves creating and transforming features to improve model performance. It consists of feature creation, transformation, and extraction, along with exploratory data analysis.\n",
    "*   **Feature selection** is a process of selecting the most relevant features for a model.\n",
    "*   Dimensionality reduction is a technique used to reduce the number of features in a dataset, improving its comprehensibility.\n",
    "*   Tools like FeatureTools, TsFresh, and OneBM can be used for feature engineering.\n",
    "\n",
    "**Machine Learning**\n",
    "*   **Classification** is the activity of assigning objects to pre-existing classes or categories.\n",
    "*  **Regression analysis** is a set of statistical processes for estimating the relationships among variables.\n",
    "*   **Supervised learning** involves training models on labeled data, whereas **unsupervised learning** works with unlabeled data.\n",
    "*   Common machine learning algorithms include Linear Regression, Logistic Regression, Decision Trees, Naive Bayes, Random Forest, Support Vector Machines, K-Means, K-Nearest Neighbors, Dimensionality Reduction, and Artificial Neural Networks.\n",
    "*   **Naive Bayes** classifiers assign labels based on probability.\n",
    "*   **Support Vector Machines (SVM)** are used for classification, regression, and sorting by finding the optimal hyperplane in a dataset.\n",
    "*   **Large language models (LLMs)** can be used in data science to understand user queries, generate code, and enhance the interpretability of predictive AI models.\n",
    "*   **Fine-tuning** is a technique used to adapt pre-trained LLMs to specific tasks, incorporating proprietary data.\n",
    "\n",
    "**Python Libraries**\n",
    "*   **Pandas** is a library for structured data operations such as importing CSV files, creating dataframes, and data preparation.\n",
    "*   **NumPy** is a mathematical library for arrays, linear algebra, and Fourier transforms. NumPy is used for numerical analysis, array manipulation, descriptive statistics, and it forms the basis of other libraries.\n",
    "*   **Matplotlib** is a library for creating data visualizations such as charts and graphs. It has diverse functions for creating line plots, scatter plots, histograms, pie charts, and box plots.\n",
    "*   **Seaborn** is a statistical data visualization library built on Matplotlib that offers simplicity and unique features. Seaborn is better integrated with Pandas data frames.\n",
    "*   **SciPy** is a library for complex mathematical calculations and scientific problems, and it also includes linear algebra modules.\n",
    "*  **Scikit-learn** is a machine learning library built on NumPy and SciPy, with access to a variety of algorithms and statistical models. It is used to create visualizations based on machine learning models and for predictive analytics.\n",
    "\n",
    "**Other Important Concepts**\n",
    "*   **Data cleansing** is the process of correcting or removing inaccurate or inconsistent data.\n",
    "*   **Survivorship bias** is a type of selection bias where only the successful outcomes of a process are visible.\n",
    "\n",
    "This summary highlights the main themes and tools discussed in Week 01 - Introduction, offering a broad view of data science and related fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpEY4fZw9cYe"
   },
   "source": [
    "## Data\n",
    "\n",
    "From Wikipedia (https://en.m.wikipedia.org/wiki/Data):\n",
    "* A set of values of qualitative or quantitative variables about one or more persons or objects\n",
    "* A datum (singular of data) is a single value of a single variable\n",
    "* Although the terms \"data\" and \"information\" are often used interchangeably, data are sometimes said to be transformed into information when they are viewed in context or in post-analysis\n",
    "* Data are measured, collected, reported, and analyzed, and used to create data visualizations such as graphs, tables or images\n",
    "* Data as a general concept refers to the fact that some existing information or knowledge is represented or coded in some form suitable for better usage or processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d20ec3c"
   },
   "source": [
    "## Science\n",
    "\n",
    "From Wikipedia (https://en.m.wikipedia.org/wiki/Science):\n",
    "* Modern science is commonly divided into three major branches: natural science, social science, and formal science\n",
    "* Logic, mathematics, statistics, and computer science are listed under formal science\n",
    "* Formal science is an area of study that generates knowledge using formal systems\n",
    "* Formal science is a priori, knowledge which is independent of experience\n",
    "* Scientific method involves using the scientific method, which seeks to objectively explain the events of nature in a reproducible way\n",
    "* The steps listed for the scientific method vary from text to text but usually include, a) define the problem, b) gather background information, c) form a hypothesis, d) make observations, e) test the hypothesis, and f) draw conclusions. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1635141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcaa9c60"
   },
   "source": [
    "## Data Science\n",
    "\n",
    "From Wikipedia (https://en.m.wikipedia.org/wiki/Data_science):\n",
    "* Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains\n",
    "* SQL, Data Management, Programming, and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d0af2a1"
   },
   "source": [
    "## Domain\n",
    "* Data Analysis\n",
    "* Machine Learning\n",
    "* Artificial Intelligence\n",
    "* Math\n",
    "* Statistics\n",
    "* Computer Science\n",
    "* Information Technology\n",
    "* Business Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c727ab1"
   },
   "source": [
    "## Some Tools\n",
    "\n",
    "* R\n",
    "* SPSS\n",
    "* SAS\n",
    "* Excel\n",
    "* Power BI\n",
    "* Tableau\n",
    "* Python (Colab)\n",
    "* SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00bfba26"
   },
   "source": [
    "## Statistical Learning vs Machine Learning\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Statistical Learning</th>\n",
    "<th>Machine Learning</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style='text-align: left;'>\n",
    "<ul>\n",
    "<li>Statistical significance / tests</li>\n",
    "<li>Strong explanatory power</li>\n",
    "<li>ANOVA, t-test</li>\n",
    "<li>Model diagnostics, model building </li>\n",
    "<li>Model selection (forward selection, backward selection, stepwise selection)</li>\n",
    "<li>Evaluation (AIC, BIC)</li>\n",
    "<li>Standard transformations (e.g. Box-Cox)</li>\n",
    "<li>Residual analysis</li>\n",
    "<li>Generalized linear models (GLM)</li>\n",
    "<li>Longitudinal data, time series</li>\n",
    "<li>Experimental design</li>\n",
    "<li>Covariates, predictors, outcomes, independent / dependent variables</li>\n",
    "<li>Normal distribution</li>\n",
    "<li>Interpretation</li>\n",
    "<li>Regression Analysis </li>\n",
    "</ul>          \n",
    "</td>    \n",
    "<td style='text-align: left;'>\n",
    "<ul>\n",
    "<li>Loss function</li>\n",
    "<li>Minimizing the loss function</li>\n",
    "<li>Train and test sets</li>\n",
    "<li>High predictive accuracy</li>\n",
    "<li>Hyperparameters, generalization, overfitting, regularization</li>\n",
    "<li>Inputs and outputs (targets)</li>\n",
    "<li>Gaussian distribution</li>\n",
    "<li>Implementation</li>\n",
    "<li>Linear Regression</li>\n",
    "<li>Calculus</li>\n",
    "<li>Python</li>\n",
    "<li>Linear algebra (vectors, matrices)</li>\n",
    "<li>Probability</li>\n",
    "</ul>        \n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5cfbc70"
   },
   "source": [
    "## Data Science Process\n",
    "\n",
    "https://www.springboard.com/blog/wp-content/uploads/2022/05/data-science-life-cycle.png\n",
    "\n",
    "* Understanding the problem and getting the data\n",
    "* Data preparation and exploratory data analysis\n",
    "* Feature engineering\n",
    "* Feature selection\n",
    "* Model selection\n",
    "* Model training\n",
    "* Model testing\n",
    "* Model tuning\n",
    "* Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02e8c4d6"
   },
   "source": [
    "## Statistics\n",
    "\n",
    "* Drawing a sample from a population and inferring characteristics from that sample to the population\n",
    "* A statistic describes a sample, a parameter describes a population\n",
    "* Data is a human artifact\n",
    "* Limited in capacity to describe the world\n",
    "* Limited because of variablility\n",
    "* Much is based on Summary data - the average and deviations\n",
    "* Airplane seats and airplane bullet holes\n",
    "* https://dlm-econometrics.blogspot.com/2020/04/the-average-man.html\n",
    "* https://en.wikipedia.org/wiki/Survivorship_bias\n",
    "* Visualizations and story telling\n",
    "* Distinguishing between chance and pattern\n",
    "* https://en.wikipedia.org/wiki/Statistics\n",
    "* https://en.wikipedia.org/wiki/History_of_statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNy4Q6n4cHKN"
   },
   "source": [
    "## History Brief: 1700s - 1800s\n",
    "\n",
    "* **1700:** Isaac Newton introduces an early form of linear regression analysis while studying equinoxes. He averages data, sums residuals to zero, and distinguishes between different types of data.\n",
    "* **1731:** Development of the sextant improves navigation and mapping.\n",
    "* **Mid-1700s:**  Taking the arithmetic mean of measurements becomes common practice in astronomy and navigation.\n",
    "* **1748-1750:** Tobias Mayer uses lunar observations to determine the moon's libration and devises a method for combining inconsistent equations.\n",
    "* **1749:** Leonhard Euler writes about inequalities in the motion of Saturn and Jupiter.\n",
    "* **1750:** Mayer introduces the symbol ±x for errors in measurement.\n",
    "* **1755:**  Christopher Maire and Roger Joseph Boscovich publish results on measuring a meridian arc.\n",
    "* **1763:** James Short develops a method for averaging measurements that discounts outliers.\n",
    "* **1773:** Lambert observes a reversal in the retardation of Saturn's motion.\n",
    "* **1787:** Laplace extends Mayer's method for reconciling inconsistent equations.\n",
    "* **1789:** Laplace adds an analytical framework to Boscovich's work, calling it the \"Method of Situation.\"\n",
    "* **1792:** Legendre joins the French commission for measuring the length of a meridian quadrant.\n",
    "* **1795:** A French commission measures the meridian arc from Barcelona to Dunkirk. Gauss claims to have been using the method of least squares.\n",
    "* **Late 1700s:** Scientists shift their view towards combining observations made under different conditions for comparing theory and experience.\n",
    "* **1805:** Legendre publishes the method of least squares in \"Nouvelles méthodes pour la détermination des orbites des comètes.\"\n",
    "* **1809:** Gauss also publishes the method of least squares.\n",
    "* **1821:** Gauss further develops the theory of least squares, including a version of the Gauss-Markov theorem.\n",
    "* **1820s:** The method of least squares becomes a standard tool in astronomy and geodesy.\n",
    "* **1831:** Mary Somerville describes Laplace's method as an alternative to least squares.\n",
    "* **19th Century:** Francis Galton coins the term \"regression\" to describe a biological phenomenon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7d3XV6pUsmf"
   },
   "source": [
    "## Sources\n",
    "\n",
    "Data Science and Statistics, Probability, and Distributions\n",
    "* https://catalog.yale.edu/ycps/subjects-of-instruction/statistics/\n",
    "* https://datascience.virginia.edu/news/how-much-do-data-scientists-need-know-about-statistics\n",
    "* https://www.seldon.io/supervised-vs-unsupervised-learning-explained\n",
    "* https://probability4datascience.com/\n",
    "* https://www.institutedata.com/us/blog/what-is-probability-theory-in-data-science/\n",
    "* https://blog.dailydoseofds.com/p/11-essential-distributions-that-data\n",
    "* https://ori.hhs.gov/education/products/n_illinois_u/datamanagement/dctopic.html\n",
    "\n",
    "Data Science Process\n",
    "* https://www.springboard.com/blog/wp-content/uploads/2022/05/data-science-life-cycle.png\n",
    "* https://www.institutedata.com/us/blog/5-steps-in-data-science-lifecycle/\n",
    "* https://en.wikipedia.org/wiki/Data_cleansing\n",
    "* https://en.wikipedia.org/wiki/Exploratory_data_analysis\n",
    "* https://builtin.com/articles/feature-engineering\n",
    "* https://www.heavy.ai/technical-glossary/feature-selection\n",
    "* https://en.wikipedia.org/wiki/Regression_analysis\n",
    "* https://www.nobledesktop.com/classes-near-me/blog/top-algorithms-for-data-science\n",
    "* https://en.wikipedia.org/wiki/Classification\n",
    "* https://www.ibm.com/think/topics/fine-tuning\n",
    "* https://www.thoughtspot.com/data-trends/best-practices/data-storytelling\n",
    "\n",
    "Data Science and Python\n",
    "* https://www.nobledesktop.com/classes-near-me/blog/why-learn-numpy-for-data-science\n",
    "* https://www.nvidia.com/en-us/glossary/pandas-python/\n",
    "* https://www.nobledesktop.com/classes-near-me/blog/why-learn-matplotlib-for-data-science\n",
    "* https://datascientest.com/en/seaborn-everything-you-need-to-know-about-the-python-data-visualization-tool\n",
    "* https://www.nobledesktop.com/classes-near-me/blog/why-learn-scikit-learn-for-data-science\n",
    "* https://datascientest.com/en/scipy-all-about-the-python-machine-learning-library\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d59397d"
   },
   "source": [
    "## Books\n",
    "\n",
    "* Everybody Lies: Big Data, New Data, and What the Internet Can Tell Us About Who We Really Are by Seth Stephens-Davidowitz\n",
    "* Naked Statistics: Stripping the Dread from the Data 1st Edition by Charles Wheelan\n",
    "* Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy by Cathy O'Neil\n",
    "* The Art of Statistics: How to Learn from Data by David Spiegelhalter\n",
    "* The Drunkard's Walk: How Randomness Rules Our Lives by Leonard Mlodinow, Sean Pratt, et al.\n",
    "* The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World by Pedro Domingos\n",
    "* The Book of Why by Judea Pearl and Dana MacKenzie\n",
    "* The History of Statistics by Stephen Stigler\n",
    "* The End of Average by Todd Rose\n",
    "* Outliers by Malcom Gladwell\n",
    "* Freakonomics by Stephen J. Dubner and Steven Levitt\n",
    "* Thinking in Bets by Annie Duke\n",
    "* The Signal in the Noise by Nate Silver\n",
    "* Data Science for Business by Foster Provost and Tom Fawcett\n",
    "* Story Telling with Data by Cole Nussbaum Knaflic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hQJVn_A_h01"
   },
   "source": [
    "## Data Science and Python Online Books\n",
    "\n",
    "* https://www.statlearning.com/ (all lectures on YouTube)\n",
    "* https://jakevdp.github.io/PythonDataScienceHandbook/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOTs/XrM0KmqZR77btyFwv2",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
